{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3678124",
   "metadata": {},
   "source": [
    "# Simple binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53086d25",
   "metadata": {},
   "source": [
    "In this notebook we study the classification problem using different techniques and a dataset based on sonar-based object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ae7a3",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "The Sonar Dataset involves the prediction of whether or not an object is a mine or a rock given the\n",
    "strength of sonar returns at different angles. It is a binary (2-class) classification problem. The\n",
    "number of observations for each class is not balanced. There are 208 observations with 60 input\n",
    "variables and 1 output variable.\n",
    "\n",
    "The file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar\n",
    "signals off a metal cylinder at various angles and under various\n",
    "conditions.  The file \"sonar.rocks\" contains 97 patterns obtained from\n",
    "rocks under similar conditions.  The transmitted sonar signal is a\n",
    "frequency-modulated chirp, rising in frequency.  The data set contains\n",
    "signals obtained from a variety of different aspect angles, spanning 90\n",
    "degrees for the cylinder and 180 degrees for the rock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe33a7",
   "metadata": {},
   "source": [
    "## Code requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e82ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using DataFramesMeta # Regressions\n",
    "using CSV\n",
    "using StatsBase\n",
    "using GLM # Regressions\n",
    "using MLJ # Knn\n",
    "using LIBSVM #SVM\n",
    "using Printf\n",
    "using NearestNeighborModels # Knn\n",
    "using MLJBase #Knn\n",
    "using DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0569f",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294cc87",
   "metadata": {},
   "source": [
    "The data set is processed and divided into two parts:\n",
    "- A first section consisting of 70 random samples of objects classified as mines and 70 more of objects classified as rocks.\n",
    "- A training section containing the remaining elements of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "370b320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myPath = \"Data/sonar.csv\"\n",
    "function trainingSelection(n, path=myPath)\n",
    "    \n",
    "    sonarRaw = CSV.read(path, DataFrame)\n",
    "    sonar = sort!(sonarRaw, [:61])\n",
    "    \n",
    "    k = size(sonar,1)\n",
    "    m = findfirst(isequal(\"R\"), sonar[!,:61])\n",
    "    \n",
    "    if (n > (k-m) || n > (m-1))\n",
    "        print(\"There is insufficient data for a balanced sample of n \")\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    RowsMine = sample(1:(m-1), n, replace=false, ordered=true) # Muestra de indices aleatorios donde la linea tiene clasificación M\n",
    "    sonarMine = sonar[RowsMine, :] # Dadaframe con las filas resultantes de RowsMine\n",
    "    \n",
    "    RowsRock = sample(m:k, n, replace=false, ordered=true) # Muestra de indices aleatorios donde la linea tiene clasificación R\n",
    "    sonarRock = sonar[RowsRock, :] #  Dadaframe con las filas resultantes de RowsMine\n",
    "    \n",
    "    testData = sonar[Not(union(RowsMine, RowsRock)),:] # Dataframe con las filas que no estan ni en RowsMine ni RowsRock\n",
    "    \n",
    "    trainingData = vcat(sonarMine, sonarRock); # Union de sonarMine con sonarRock (Conjunto de entrenamiento)\n",
    "    \n",
    "    return trainingData, testData # training = 140 -> 70 and 70, test = 68 -> 41 and 27\n",
    "    \n",
    "end\n",
    "\n",
    "# Dump separated data\n",
    "\n",
    "out = trainingSelection(70)\n",
    "training = out[1]\n",
    "testing = out[2]\n",
    "\n",
    "training.\"f61\".= replace.(training.\"f61\", \"M\" => \"1\")\n",
    "training.\"f61\".= replace.(training.\"f61\", \"R\" => \"0\")\n",
    "training.\"f61\" = parse.(Float64, training.\"f61\")\n",
    "\n",
    "testing.\"f61\".= replace.(testing.\"f61\", \"M\" => \"1\")\n",
    "testing.\"f61\".= replace.(testing.\"f61\", \"R\" => \"0\")\n",
    "testing.\"f61\" = parse.(Float64, testing.\"f61\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d152bfb",
   "metadata": {},
   "source": [
    "Additionally the representation of the two classes by positive cases (mines -> 1) and negative cases (rocks -> 0) is transformed and the data is dumped into two new files to persist the data in case of further testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b3d8b",
   "metadata": {},
   "source": [
    "## Dump Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "53f0c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"Data/training.csv\", training)\n",
    "CSV.write(\"Data/test.csv\", testing);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af94bd",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "It is determined that **accuracy** will be the metric used to evaluate the performance of the machines to be considered:\n",
    "\n",
    "Accuracy is one of the metrics for evaluating classification models in ML. It can be explained as the fraction of predictions that our model got right. Formally, we define it as follows:\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "Where TP = True Positives, TN = True Negatives, FP = False Positives, and FN = False Negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec719cb",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "With the data processed and separated into training and testing, we proceed to study the following algorithms applied to this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba7ccc",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8a368f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.118%\n"
     ]
    }
   ],
   "source": [
    "fm = @formula(f61 ~ f1+f2+f3+f4+f5+f6+f7+f8+f9+f10+f11+f12+f13+f14+f15+f16+f17+f18+f19+f20+f21+f22+f23+f24+f25+f26+f27+f28+f29+f30+f31+f32+f33+f34+f35+f36+f37+f38+f39+f40+f41+f42+f43+f44+f45+f46+f47+f48+f49+f50+f51+f52+f53+f54+f55+f56+f57+f58+f59+f60)\n",
    "linearRegressor = lm(fm, training)\n",
    "prediction = GLM.predict(linearRegressor, testing)\n",
    "prediction_class = [if x < 0.5 0 else 1 end for x in prediction]\n",
    "# Falta generar métrica\n",
    "@printf \"Accuracy: %.3f%%\\n\" mean((prediction_class .== testing.\"f61\"))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5bd1f9",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53573ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.471%\n"
     ]
    }
   ],
   "source": [
    "logit = glm(fm, training, Binomial(), ProbitLink())\n",
    "prediction = GLM.predict(logit,testing)\n",
    "prediction_class = [if x < 0.5 0 else 1 end for x in prediction]\n",
    "# Falta generar métrica\n",
    "@printf \"Accuracy: %.3f%%\\n\" mean((prediction_class .== testing.\"f61\"))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ed9b6",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8ccd839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.000%\n"
     ]
    }
   ],
   "source": [
    "X = Matrix(training[:,1:60])'\n",
    "y = training.\"f61\"\n",
    "\n",
    "test = Matrix(testing[:,1:60])'\n",
    "ytest = testing.\"f61\"\n",
    "\n",
    "model = svmtrain(X, y)\n",
    "ŷ, decision_values = svmpredict(model, test)\n",
    "\n",
    "# Compute accuracy\n",
    "@printf \"Accuracy: %.3f%%\\n\" mean((ŷ .== ytest))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10071b02",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d9c19d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.412%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{KNNClassifier,…}.\n",
      "└ @ MLJBase /home/angel/.julia/packages/MLJBase/rMXo2/src/machines.jl:423\n"
     ]
    }
   ],
   "source": [
    "using NearestNeighborModels, MLJBase\n",
    "\n",
    "complete = vcat(training,testing)\n",
    "X = MLJ.table(Matrix(complete[:,1:60]))\n",
    "y = categorical(complete.\"f61\")\n",
    "\n",
    "knnc = KNNClassifier() \n",
    "knnc_mach = machine(knnc, X, y) # MLJ Machine\n",
    "MLJBase.fit!(knnc_mach, rows=1:140) # train machine on a subset of the wrapped data `X`\n",
    "\n",
    "p = predict_mode(knnc_mach, rows=141:208)\n",
    "# Falta generar métrica\n",
    "@printf \"Accuracy: %.3f%%\\n\" mean((p .== testing.\"f61\"))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123a6f8",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "635c6b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.706%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTree.DecisionTreeClassifier(max_depth=2)\n",
    "fit!(model, Matrix(training[:,1:60]), training.\"f61\")\n",
    "\n",
    "p = predict(model, Matrix(testing[:,1:60]))\n",
    "prediction_class = [if x < 0.5 0 else 1 end for x in p]\n",
    "\n",
    "@printf \"Accuracy: %.3f%%\\n\" mean((prediction_class .== testing.\"f61\"))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b85e3",
   "metadata": {},
   "source": [
    "## Best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba35dc",
   "metadata": {},
   "source": [
    "Each implementation of the algorithms considers the calculation of performance metrics. We see then that in this case the Knn algorithm is the one that best classified the training data (with an accuracy of 79.412%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f23fed",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
